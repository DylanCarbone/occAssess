---
title: "occAssess"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{occAssess}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
#install_github("https://github.com/robboyd/occAssess")
library(occAssess)
```

# Introduction

# What does occAssess do? 

occAssess enables quick and easy screening of species occurrence data for common forms of bias and uncertainty. 

## How does it work? 

The package comprises a number of discrete functions, each of which is designed to assess a common form of bias or uncertainty, or indicate poor coverage. Generally speaking, users must simply pass their occurrence data to the functions, and specify time periods into which the resulting metrics will be split. Ouputs are provided in list format, with one element containing a ggplot2 object, and a second containing the data that underpins that plot.

## A worked example 

In this document I demonstrate the utility of occAssess by applying it to data on pollinator occurrences in South America over the period 1950 to 2019. The data were extracted from GBIF using the rgbif function occ_data. I come at the data from the perspective of a modeller interested in estimating how the species' distributions have changed over time. 

### Inputs

#### Occurrence data

occAssess requires a data.frame with the following fields: species (species name), x (x coordinae of record), y (y coordinate), year, spatialUncertainty (how much uncertainty is associated with the x and y coordinates; units do not matter but must be consistent) and identifier. The identifier is used to split the data into groups; for example, it could represent taxonomic groups or specific datasets. Where you have no information for a field, its value should be set to NA. 

```{r eval = TRUE}

spDat <- read.csv("C:/Users/Rob.Lenovo-PC/Documents/surpass/Data/GBIF/20.01.21/allDat.csv")

str(spDat)

```

#### Periods

In addition to your occurrence data, you must also provide a number of periods into which your data will be split (thi can be one period covering e.g. your whole study extent). In this example I will split the data into (roughly) decades over the period 1950 to 2019. Periods are defined as follows:

```{r eval = TRUE}

periods <- list(1950:1960, 1961:1970, 1971:1980, 1981:1990, 1991:2000, 2001:2010, 2011:2019)

```

### Functions

All of the functions in occAssess require two common arguments: dat and periods (outlined above). I will run through each function in the following, indicating where additional arguments are required. Generally, the functions in occAssess return a list with two elements: one being a ggplot2 object, with a separate panel for each level of identifier; and a second with the data underpinning the plot.

#### assessRecordNumber

The first function I will introduce is the simplest: assessRecordNumber. This function simply plots out the number of records per year in your dataset. 

```{r eval = TRUE, fig.width = 7}

nRec <- assessRecordNumber(dat = spDat,
                           periods = periods)

str(nRec$data)

nRec$plot

```

This function enables researchers to quickly establish how the number of records has changed over time. 

#### assessSpeciesNumber 

In addition to the number of records, you may wish to know how the number of species (taxonomic coverage) in your dataset changes over time. For this you can use the function assessSpeciesNumber:

```{r eval = TRUE, fig.width = 7}

nSpec <- assessSpeciesNumber(dat = spDat,
                           periods = periods)

str(nSpec$data)

nSpec$plot

```

#### assessSpeciesID 

It has been speculated that apparent changes in taxonomic coverage could, in fact, reflect a change in taxonomic expertise over time. For example, if fewer individuals have the skill to identify certain species, then it may not appear in your dataset in the later periods. The function assessSpeciesID treats the proportion of species identified to species level as a proxy for taxonomic expertise: 

```{r eval = TRUE, fig.width = 7}

propID <- assessSpeciesID(dat = spDat,
                           periods = periods,
                           type = "proportion")

str(propID$data)

propID$plot

```

The argument "type" can take the values proportion (proportion of records identified to species level) or count (number of records identified to species level). 

#### assessSpatialCov 

The function assessSpatialCov grids your data at a specified spatial resolution then maps it in geographic space:

```{r eval = TRUE, fig.width = 7}

assessSpatialCov(dat = spDat,
                 periods = periods,
                 res = 0.5,
                 logCount = TRUE,
                 countries = c("Brazil", "Argentina", "Chile", "Colombia", "Ecuador", "Bolivia", "Uruguay", 
                 "Venezuela", "Guayana", "Paraguay", "Peru", "Suriname"))

```

As you can see there are three new arguments to be specified. res is the spatial resolution at which you would like to map the data (units depend on you coordinate reference system, e.g. m if easting and northing, and decimal degress in lon/ lat); logCount indicates whether or not you would like to log10 transform the counts for visual purposes; and countries defines the countries covered by your data. Countries must be specified in order to plot their boundaries.

#### assessSpatialUncertainty 

Point occurrence data often comes with assocatiated spatial uncertainty (i.e. how uncertain the coordinates are in x and y dimensions). For example, GBIF data comes with a field called coorinateUncertaintyInMeters. The function assessSptialUncertainty can be used to visualize spatial uncertainty in your dataset:

```{r eval = TRUE, fig.width = 7}

assessSpatialUncertainty(dat = spDat,
                         periods = periods)

```

#### assessSpatialBias

Even if your data has good spatial coverage, it may be biased; that is to say, it may deviate from a random distribution in space. The function assessSpatialBias provides an index of how far your data deviates from a random distribution. To do this is simulates an equal number of points to your data randomly across your study region. Then, for each time period, it calculates the average nearest neighbour distance across your data points and divides it by the average nearest neighbour distance from the random sample. If the index is lower than one then your data is more clustered than the random sample, and if it is above one it is more dispersed. To delineate your study area, you must provide a mask layer. The mask is a raster object which is has numeric values within your study area, and is NA outside of your study area. Here, I'll use some climate data from South America as a mask layer:

```{r eval = TRUE, fig.width = 7}

mask <- raster::raster("C:/Users/Rob.Lenovo-PC/Documents/surpass/Data/occAssessData/climSA.asc")

mask

```

```{r eval = TRUE, fig.width = 7}

spatBias <- assessSpatialBias(dat = spDat,
                              periods = periods,
                              mask = mask,
                              nSamps = 10,
                              degrade = TRUE)

str(spatBias$data)

spatBias$plot

```

The argument nSamps indicates how many random distributions should be drawn, and the argument degrade = TRUE indicates that any duplicated coordinates within a time period and for a given level of identifier are removed. The shaded regions on the plot indicate the 5th and 95th percentiles of the nearest neighbour index calculated over nSamps random samples. 

#### assessEnvBias 

Spatial bias in your dataset does not necessarily tell you anything about environmental bias. The function assessEnvBias assess the degree to which your data are biased across time periods in environmental space. To do this we first need to get some climate data. I will use the standard suite of 19 bioclimatic variables from worldclim. It is possible to get this data through R using the raster package, but here I will use my local version for speed:

```{r eval = TRUE, fig.width = 7}
## How to get the data using raster::getData()

#clim <- raster::getData("worldclim",var="bio",res=10)

clim <- raster::stack(list.files("C:/Users/Rob.Lenovo-PC/Documents/surpass/Data/bio/bio/",
                           full.names = T))

spDat <- cbind(spDat, raster::extract(clim, spDat[, c("lon", "lat")]))

```
assessEnvBias conducts a principal component analysis on your environmental data, then maps your occurrence data in environmental space:

```{r eval = TRUE, fig.width = 7}

envBias <- assessEnvBias(dat = spDat,
                         periods = periods,
                         nEnvVar = 19,
                         frame = TRUE,
                         frame.type = "norm")

str(envBias$pca)
envBias$plot

```
It is also possible to modify the appearance of envBias$plot using additional arguments that can be passed to ggbiplot::ggbiplot or ggfortify::autoplot.pca. For example, you can include elipses, use different principal components, include vaiable vectors, etc. 
